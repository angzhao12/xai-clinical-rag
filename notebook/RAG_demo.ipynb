{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y langchain langchain-community langchain-openai langchain-groq chromadb sentence-transformers numpy scipy scikit-learn > /dev/null\n",
        "\n",
        "!pip -q install \\\n",
        "  \"numpy==1.26.4\" \"scipy==1.11.4\" \"scikit-learn==1.3.2\" \"sentence-transformers==2.7.0\" \\\n",
        "  \"langchain==0.2.16\" \"langchain-community==0.2.16\" \"langchain-groq==0.1.6\" \\\n",
        "  \"chromadb==0.5.5\" \"pypdf==4.3.1\" \\\n",
        "  \"langchain-huggingface==0.0.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ21GRnKBNC4",
        "outputId": "4d888ceb-b060-47e9-b34a-a7cbe24ac457"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "mapclassify 2.10.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.38.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "esda 2.8.1 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "esda 2.8.1 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "imbalanced-learn 0.14.1 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "giddy 2.3.8 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "pointpats 2.5.5 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.11.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "spopt 0.7.0 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray-einstats 0.10.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray-einstats 0.10.0 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "inequality 1.1.2 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "libpysal 4.14.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "libpysal 4.14.1 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install + upload + key"
      ],
      "metadata": {
        "id": "FRA0Ei79M4cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, shutil\n",
        "from getpass import getpass\n",
        "from google.colab import files\n",
        "\n",
        "# Modern LangChain Import Paths\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Use underscore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "print(\"Please upload your PDF file:\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "PERSIST_DIR = \"./chroma_db\"\n",
        "if os.path.exists(PERSIST_DIR):\n",
        "    shutil.rmtree(PERSIST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "iShiga0pQzTf",
        "outputId": "48b19f60-1741-435b-bbe6-05d3d0319277"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6071a204-3838-49f0-922b-2f8e2139d600\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6071a204-3838-49f0-922b-2f8e2139d600\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving ver 6.0.pdf to ver 6.0 (1).pdf\n",
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load PDF\n",
        "loader = PyPDFLoader(file_name)\n",
        "docs = loader.load()\n",
        "\n",
        "# 2) Chunking\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(\"Total chunks:\", len(chunks))\n",
        "\n",
        "# 3) Local Embeddings (HF)\n",
        "# Good default: small, fast, decent quality\n",
        "hf_emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# 4) Vector DB (local)\n",
        "vector_db = Chroma.from_documents(chunks, hf_emb, persist_directory=PERSIST_DIR)\n",
        "\n",
        "# 5) Anti-hallucination prompt\n",
        "prompt_template = \"\"\"You must answer ONLY using the provided context.\n",
        "If the answer is not contained in the context, say: \"I don't know based on the provided documents.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "QA_PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# 6) Groq LLM (fast)\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "# 7) RAG chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 6,\"fetch_k\": 20, \"lambda_mult\": 0.6}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_PROMPT},\n",
        ")\n",
        "\n",
        "# 8) Test questions\n",
        "questions = [\n",
        "    \"Why is explainability critical in clinical decision support (CDS)?\",\n",
        "    \"What challenges or obstacles does the document describe for implementing explainable CDS in real clinical settings?\",\n",
        "    \"Does this document mention Starbucks rewards? (Negative test)\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"QUERY:\", q)\n",
        "    resp = qa_chain.invoke({\"query\": q})\n",
        "    print(\"\\nANSWER:\\n\", resp[\"result\"])\n",
        "    print(\"\\nSOURCES:\")\n",
        "    for i, d in enumerate(resp[\"source_documents\"], 1):\n",
        "        page = d.metadata.get(\"page\", \"N/A\")\n",
        "        snippet = d.page_content.replace(\"\\n\",\" \")[:160]\n",
        "        print(f\"  [{i}] Page {page}: {snippet}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yyRZ8Rw7EVS",
        "outputId": "c5ae8131-5016-45bf-d341-48dd194d0fdd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "QUERY: Why is explainability critical in clinical decision support (CDS)?\n",
            "\n",
            "ANSWER:\n",
            " Explainable AI (XAI) promises two linked benefits: (1) greater trust by clinicians and patients and (2) smoother implementation into workflows governed by regulation, liability, and professional norms.\n",
            "\n",
            "SOURCES:\n",
            "  [1] Page 3: ExplanationOfDecision  profile, enabling machine -readable provenance that  dovetails with audit -trail requirements.   Third, p ayers stand to gain: if explain...\n",
            "  [2] Page 4: 6  Recommendations (2025 -2030)   Table  2 summari zes near-term actions for the four stakeholder groups most able to  accelerate explainable  CDS adoption. The...\n",
            "  [3] Page 0: accompany an automated recommendation with a human -understandable rationale.  Applied to clinical -decision -support  (CDS) systems, XAI promises two linked be...\n",
            "  [4] Page 4: Educators  Integrate XAI literacy into clinical -reasoning curricula;  offer micro -credentials.   7  Conclusion   Explainable  CDS is not a single product but ...\n",
            "  [5] Page 0: Explainable Clinical -Decision -Support  AI: A 30 -Year Outlook Through a  Sociotechnical Lens   1  Introduction   Artificial intelligence (AI) inspires extraor...\n",
            "  [6] Page 0: takes longer than you think.”   2.2 Scope and Evidence   The unit of analysis is the family of explainable  CDS tools , not a single vendor product.  The focus ...\n",
            "\n",
            "================================================================================\n",
            "QUERY: What challenges or obstacles does the document describe for implementing explainable CDS in real clinical settings?\n",
            "\n",
            "ANSWER:\n",
            " The document describes several challenges or obstacles for implementing explainable CDS in real clinical settings, including:\n",
            "\n",
            "1. Logistical nightmare without automated validation pipelines, which the FDA's proposed Predetermined Change-Control Plans aim to address.\n",
            "2. Explanations can mask deeper inequities, as a SHAP plot may faithfully report that race was not used, yet the model could still learn proxies.\n",
            "3. Explainability is necessary but not sufficient for fairness.\n",
            "4. The need for deeper overhauls of data governance, law, and human-computer interaction to support patient-facing narratives and fully auditable pipelines.\n",
            "5. The potential for expensive re-work later on if explainability is not treated as infrastructure now.\n",
            "\n",
            "SOURCES:\n",
            "  [1] Page 3: ExplanationOfDecision  profile, enabling machine -readable provenance that  dovetails with audit -trail requirements.   Third, p ayers stand to gain: if explain...\n",
            "  [2] Page 4: 6  Recommendations (2025 -2030)   Table  2 summari zes near-term actions for the four stakeholder groups most able to  accelerate explainable  CDS adoption. The...\n",
            "  [3] Page 4: Educators  Integrate XAI literacy into clinical -reasoning curricula;  offer micro -credentials.   7  Conclusion   Explainable  CDS is not a single product but ...\n",
            "  [4] Page 0: takes longer than you think.”   2.2 Scope and Evidence   The unit of analysis is the family of explainable  CDS tools , not a single vendor product.  The focus ...\n",
            "  [5] Page 3: logistical nightmare without automated validation pipelines. The FDA’s  proposed Predetermined Change -Control Plans seek to address this but remain  draft (FDA...\n",
            "  [6] Page 0: accompany an automated recommendation with a human -understandable rationale.  Applied to clinical -decision -support  (CDS) systems, XAI promises two linked be...\n",
            "\n",
            "================================================================================\n",
            "QUERY: Does this document mention Starbucks rewards? (Negative test)\n",
            "\n",
            "ANSWER:\n",
            " I don't know based on the provided documents.\n",
            "\n",
            "SOURCES:\n",
            "  [1] Page 1: Laws emerge from past mishaps, but once enacted they set entry barriers that shape all  future products. For example, the FDA draft requires human -interpretabl...\n",
            "  [2] Page 3: competitive pressure  will make adoption by 2028 realistic.   Second, w orkflow compatibility. Most early use -cases augment existing alerts;  clinicians alread...\n",
            "  [3] Page 3: logistical nightmare without automated validation pipelines. The FDA’s  proposed Predetermined Change -Control Plans seek to address this but remain  draft (FDA...\n",
            "  [4] Page 1: waterfall -plots directly in alert banners. Prospective pilots show that such displays  shave 22 –35 seconds off physicians’ decision time for routine antibioti...\n",
            "  [5] Page 2: (FDA,  2025). In the EU, Regulation  2024/1689 makes transparency a legal obligation  for all high -risk medical AI.   Implementation experience.  Early -adopte...\n",
            "  [6] Page 5: , W. C. (2020).  Alert -override patterns with a medication clinical decision -support  system in an academic emergency department:  Retrospective descriptive  ...\n"
          ]
        }
      ]
    }
  ]
}